{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "\n",
    "for yr in np.arange(2016, 2017, 1):\n",
    "    DFCB_2016 = pd.DataFrame()\n",
    "    allfiles = glob.glob(data_dir + \"/monthlydata/\" + str(int(yr)) + \"/\" + str(int(yr)) + \"*.csv\")\n",
    "    filelist = []\n",
    "    totellen = 0\n",
    "    for fili in allfiles:\n",
    "        df = pd.read_csv(fili)\n",
    "        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '')\n",
    "        ## make sure datetime format is the same ##\n",
    "        if df['starttime'].str.contains('-').any():\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "#             df['starttime'] = df['starttime'].dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "        else:\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%m/%d/%Y %H:%M:%S')\n",
    "            \n",
    "        DFCB_2016 = pd.concat([DFCB_2016,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2015 data\n",
    "import sys\n",
    "for yr in np.arange(2015, 2016, 1):\n",
    "    DFCB_2015 = pd.DataFrame()\n",
    "    allfiles = glob.glob(data_dir + \"/monthlydata/\" + str(int(yr)) + \"/\" + str(int(yr)) + \"*.csv\")\n",
    "    filelist = []\n",
    "    totellen = 0\n",
    "    for fili in allfiles:\n",
    "        df = pd.read_csv(fili)\n",
    "        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '')\n",
    "        ## make sure datetime format is the same ##\n",
    "        if df['starttime'].str.contains('-').any():\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "        elif len(df.starttime.iloc[0].split(':')) == 3:\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%m/%d/%Y %H:%M:%S')\n",
    "        else:\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%m/%d/%Y %H:%M')\n",
    "            \n",
    "        DFCB_2015 = pd.concat([DFCB_2015,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2017 data\n",
    "for yr in np.arange(2017, 2018, 1):\n",
    "    DFCB_2017 = pd.DataFrame()\n",
    "    allfiles = glob.glob(data_dir + \"/monthlydata/\" + str(int(yr)) + \"/\" + str(int(yr)) + \"*.csv\")\n",
    "    filelist = []\n",
    "    totellen = 0\n",
    "    for fili in allfiles:\n",
    "        df = pd.read_csv(fili)\n",
    "        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '')\n",
    "        ## make sure datetime format is the same ##\n",
    "        if df['starttime'].str.contains('-').any():\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%m/%d/%Y %H:%M:%S')\n",
    "            \n",
    "        DFCB_2017 = pd.concat([DFCB_2017,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2018 data\n",
    "for yr in np.arange(2018, 2019, 1):\n",
    "    DFCB_2018 = pd.DataFrame()\n",
    "    allfiles = glob.glob(data_dir + \"/monthlydata/\" + str(int(yr)) + \"/\" + str(int(yr)) + \"*.csv\")\n",
    "    filelist = []\n",
    "    totellen = 0\n",
    "    for fili in allfiles:\n",
    "        df = pd.read_csv(fili)\n",
    "        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '')\n",
    "        ## make sure datetime format is the same ##\n",
    "        if df['starttime'].str.contains('-').any():\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            df['starttime'] = pd.to_datetime(df['starttime'], format='%m/%d/%Y %H:%M:%S')\n",
    "            \n",
    "        DFCB_2018 = pd.concat([DFCB_2018,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCB_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "monthlist = []\n",
    "for i in range(1,13):\n",
    "    monthlist.append(calendar.month_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCB2 = DFCB_2015.copy()\n",
    "DFCB2 = DFCB2.set_index(['starttime'])\n",
    "DF_monthly_2015 = DFCB2.groupby(pd.Grouper(freq='M')).count().reset_index()\n",
    "DF_monthly_2015 = DF_monthly_2015.rename(columns = {'starttime':'month','tripduration':'2015_count'})\n",
    "DF_monthly_2015.month = monthlist\n",
    "DF_monthly_2015 = DF_monthly_2015[['month','2015_count']]\n",
    "\n",
    "DFCB2 = DFCB_2016.copy()\n",
    "DFCB2 = DFCB2.set_index(['starttime'])\n",
    "DF_monthly_2016 = DFCB2.groupby(pd.Grouper(freq='M')).count().reset_index()\n",
    "DF_monthly_2016 = DF_monthly_2016.rename(columns = {'starttime':'month','tripduration':'2016_count'})\n",
    "DF_monthly_2016.month = monthlist\n",
    "DF_monthly_2016 = DF_monthly_2016[['month','2016_count']]\n",
    "\n",
    "DFCB2 = DFCB_2017.copy()\n",
    "DFCB2 = DFCB2.set_index(['starttime'])\n",
    "DF_monthly_2017 = DFCB2.groupby(pd.Grouper(freq='M')).count().reset_index()\n",
    "DF_monthly_2017 = DF_monthly_2017.rename(columns = {'starttime':'month','tripduration':'2017_count'})\n",
    "DF_monthly_2017.month = monthlist\n",
    "DF_monthly_2017 = DF_monthly_2017[['month','2017_count']]\n",
    "\n",
    "\n",
    "DF_monthly_count = pd.DataFrame({'month':monthlist,'2015':DF_monthly_2015['2015_count'],\n",
    "                                 '2016':DF_monthly_2016['2016_count'], '2017':DF_monthly_2017['2017_count']})\n",
    "DF_monthly_count = DF_monthly_count.set_index('month')\n",
    "DF_monthly_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_monthly_count.to_csv('./simplified_data/2a_monthly_count.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ridership = pd.DataFrame({'year':[2015,2016,2017],\n",
    "                  'total ridership': [len(DFCB_2015),len(DFCB_2016),len(DFCB_2017)],\n",
    "                  'percentage': [len(DFCB_2015)/len(DFCB_2015),len(DFCB_2016)/len(DFCB_2015),len(DFCB_2017)/len(DFCB_2015)],\n",
    "                  'grow percentage to 2015': [0,(len(DFCB_2016)-len(DFCB_2015))/len(DFCB_2015),(len(DFCB_2017)-len(DFCB_2015))/len(DFCB_2015)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ridership.to_csv('./simplified_data/2b_year_growth.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UT_2015 = DFCB_2015.groupby('usertype')[['stoptime']].count()\n",
    "UT_2016 = DFCB_2016.groupby('usertype')[['stoptime']].count()\n",
    "UT_2017 = DFCB_2017.groupby('usertype')[['stoptime']].count()\n",
    "UserType = UT_2015.copy()\n",
    "UserType = UserType.rename(columns={'stoptime':'2015'})\n",
    "UserType['2016'] = UT_2016.stoptime\n",
    "UserType['2017'] = UT_2017.stoptime\n",
    "UserType = UserType.reset_index()\n",
    "UserType.loc[2] = ['Total', UT_2015.sum().stoptime, UT_2016.sum().stoptime, UT_2017.sum().stoptime]\n",
    "UserType = UserType.set_index('usertype')\n",
    "UserType.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserTypePercentage = UserType.copy()\n",
    "UserTypePercentage['2015'] = UserType['2015']/UserType.iloc[2,0]\n",
    "UserTypePercentage['2016'] = UserType['2016']/UserType.iloc[2,1]\n",
    "UserTypePercentage['2017'] = UserType['2017']/UserType.iloc[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserTypePercentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserType.to_csv('./simplified_data/2c_usertype.csv', sep=',')\n",
    "UserTypePercentage.to_csv('./simplified_data/2c_usertypepercentage.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "mask = (DFCB_2015['starttime'] >= datetime.datetime(2015,6,1,0,0,0)) & (DFCB_2015['starttime'] < datetime.datetime(2015,9,1,0,0,0)) \n",
    "DFCB_2015_summer = DFCB_2015.loc[mask]\n",
    "\n",
    "mask = (DFCB_2016['starttime'] >= datetime.datetime(2016,6,1,0,0,0)) & (DFCB_2016['starttime'] < datetime.datetime(2016,9,1,0,0,0)) \n",
    "DFCB_2016_summer = DFCB_2016.loc[mask]\n",
    "\n",
    "mask = (DFCB_2017['starttime'] >= datetime.datetime(2017,6,1,0,0,0)) & (DFCB_2017['starttime'] < datetime.datetime(2017,9,1,0,0,0)) \n",
    "DFCB_2017_summer = DFCB_2017.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFCB_2015_summer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_peakhour_summer = pd.DataFrame()\n",
    "times = pd.DatetimeIndex(DFCB_2015_summer.starttime)\n",
    "grouped = DFCB_2015_summer.groupby([times.hour]).tripduration.count()\n",
    "DF_peakhour_summer['2015'] = grouped\n",
    "times = pd.DatetimeIndex(DFCB_2016_summer.starttime)\n",
    "grouped = DFCB_2016_summer.groupby([times.hour]).tripduration.count()\n",
    "DF_peakhour_summer['2016'] = grouped\n",
    "times = pd.DatetimeIndex(DFCB_2017_summer.starttime)\n",
    "grouped = DFCB_2017_summer.groupby([times.hour]).tripduration.count()\n",
    "DF_peakhour_summer['2017'] = grouped\n",
    "DF_peakhour_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_peakhour_summer.to_csv('./simplified_data/2d_summerpeakhour.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "MG15_16 = pd.concat([DFCB_2015, DFCB_2016])\n",
    "MG16_17 = pd.concat([DFCB_2016, DFCB_2017])\n",
    "MG17_18 = pd.concat([DFCB_2017, DFCB_2018])\n",
    "\n",
    "mask = (MG15_16['starttime'] >= datetime.datetime(2015,12,1,0,0,0)) & (MG15_16['starttime'] < datetime.datetime(2016,3,1,0,0,0)) \n",
    "DFCB_2015_winter = MG15_16.loc[mask]\n",
    "\n",
    "mask = (MG16_17['starttime'] >= datetime.datetime(2016,12,1,0,0,0)) & (MG16_17['starttime'] < datetime.datetime(2017,3,1,0,0,0)) \n",
    "DFCB_2016_winter = MG16_17.loc[mask]\n",
    "\n",
    "mask = (MG17_18['starttime'] >= datetime.datetime(2017,12,1,0,0,0)) & (MG17_18['starttime'] < datetime.datetime(2018,3,1,0,0,0)) \n",
    "DFCB_2017_winter = MG17_18.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_peakhour_winter = pd.DataFrame()\n",
    "times = pd.DatetimeIndex(DFCB_2015_winter.starttime)\n",
    "grouped = DFCB_2015_winter.groupby([times.hour]).tripduration.count()\n",
    "DF_peakhour_winter['2015'] = grouped\n",
    "times = pd.DatetimeIndex(DFCB_2016_winter.starttime)\n",
    "grouped = DFCB_2016_winter.groupby([times.hour]).tripduration.count()\n",
    "DF_peakhour_winter['2016'] = grouped\n",
    "times = pd.DatetimeIndex(DFCB_2017_winter.starttime)\n",
    "grouped = DFCB_2017_winter.groupby([times.hour]).tripduration.count()\n",
    "DF_peakhour_winter['2017'] = grouped\n",
    "DF_peakhour_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_peakhour_winter.to_csv('./simplified_data/2e_winterpeakhour.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP10_SS_2015 = DFCB_2015.groupby(['startstationid','startstationname','startstationlongitude','startstationlatitude']).size().sort_values(ascending=False).iloc[0:10].reset_index()\n",
    "TOP10_SS_2015 = TOP10_SS_2015.rename(columns = {0:'startcount'})\n",
    "TOP10_SS_2015['startnumber'] = np.arange(1,11,1)\n",
    "TOP10_SS_2016 = DFCB_2016.groupby(['startstationid','startstationname','startstationlongitude','startstationlatitude']).size().sort_values(ascending=False).iloc[0:10].reset_index()\n",
    "TOP10_SS_2016 = TOP10_SS_2016.rename(columns = {0:'startcount'})\n",
    "TOP10_SS_2016['startnumber'] = np.arange(1,11,1)\n",
    "TOP10_SS_2017 = DFCB_2017.groupby(['startstationid','startstationname','startstationlongitude','startstationlatitude']).size().sort_values(ascending=False).iloc[0:10].reset_index()\n",
    "TOP10_SS_2017 = TOP10_SS_2017.rename(columns = {0:'startcount'})\n",
    "TOP10_SS_2017['startnumber'] = np.arange(1,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP10_SS_2015.to_csv('./simplified_data/2f_top10_SS_2015.csv', sep=',')\n",
    "TOP10_SS_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP10_SS_2016.to_csv('./simplified_data/2f_top10_SS_2016.csv', sep=',')\n",
    "TOP10_SS_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP10_SS_2017.to_csv('./simplified_data/2f_top10_SS_2017.csv', sep=',')\n",
    "TOP10_SS_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP10_ES_2015 = DFCB_2015.groupby(['endstationid','endstationname','endstationlongitude','endstationlatitude']).size().sort_values(ascending=False).iloc[0:10].reset_index()\n",
    "TOP10_ES_2015 = TOP10_ES_2015.rename(columns = {0:'endcount'})\n",
    "TOP10_ES_2015['endnumber'] = np.arange(1,11,1)\n",
    "TOP10_ES_2016 = DFCB_2016.groupby(['endstationid','endstationname','endstationlongitude','endstationlatitude']).size().sort_values(ascending=False).iloc[0:10].reset_index()\n",
    "TOP10_ES_2016 = TOP10_ES_2016.rename(columns = {0:'endcount'})\n",
    "TOP10_ES_2016['endnumber'] = np.arange(1,11,1)\n",
    "TOP10_ES_2017 = DFCB_2017.groupby(['endstationid','endstationname','endstationlongitude','endstationlatitude']).size().sort_values(ascending=False).iloc[0:10].reset_index()\n",
    "TOP10_ES_2017 = TOP10_ES_2017.rename(columns = {0:'endcount'})\n",
    "TOP10_ES_2017['endnumber'] = np.arange(1,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP10_ES_2015.to_csv('./simplified_data/2g_top10_ES_2015.csv', sep=',')\n",
    "TOP10_ES_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP10_ES_2016.to_csv('./simplified_data/2g_top10_ES_2016.csv', sep=',')\n",
    "TOP10_ES_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP10_ES_2017.to_csv('./simplified_data/2g_top10_ES_2017.csv', sep=',')\n",
    "TOP10_ES_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT10_SS_2015 = DFCB_2015.groupby(['startstationid','startstationname','startstationlongitude','startstationlatitude']).size().sort_values(ascending=True).iloc[0:10].reset_index()\n",
    "BOT10_SS_2015 = BOT10_SS_2015.rename(columns = {0:'startcount'})\n",
    "BOT10_SS_2015['startnumber'] = np.arange(1,11,1)\n",
    "BOT10_SS_2016 = DFCB_2016.groupby(['startstationid','startstationname','startstationlongitude','startstationlatitude']).size().sort_values(ascending=True).iloc[0:10].reset_index()\n",
    "BOT10_SS_2016 = BOT10_SS_2016.rename(columns = {0:'startcount'})\n",
    "BOT10_SS_2016['startnumber'] = np.arange(1,11,1)\n",
    "BOT10_SS_2017 = DFCB_2017.groupby(['startstationid','startstationname','startstationlongitude','startstationlatitude']).size().sort_values(ascending=True).iloc[0:10].reset_index()\n",
    "BOT10_SS_2017 = BOT10_SS_2017.rename(columns = {0:'startcount'})\n",
    "BOT10_SS_2017['startnumber'] = np.arange(1,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT10_SS_2015.to_csv('./simplified_data/2h_bot10_SS_2015.csv', sep=',')\n",
    "BOT10_SS_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT10_SS_2016.to_csv('./simplified_data/2h_bot10_SS_2016.csv', sep=',')\n",
    "BOT10_SS_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT10_SS_2017.to_csv('./simplified_data/2h_bot10_SS_2017.csv', sep=',')\n",
    "BOT10_SS_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT10_ES_2015 = DFCB_2015.groupby(['endstationid','endstationname','endstationlongitude','endstationlatitude']).size().sort_values(ascending=True).iloc[0:10].reset_index()\n",
    "BOT10_ES_2015 = BOT10_ES_2015.rename(columns = {0:'endcount'})\n",
    "BOT10_ES_2015['endnumber'] = np.arange(1,11,1)\n",
    "BOT10_ES_2016 = DFCB_2016.groupby(['endstationid','endstationname','endstationlongitude','endstationlatitude']).size().sort_values(ascending=True).iloc[0:10].reset_index()\n",
    "BOT10_ES_2016 = BOT10_ES_2016.rename(columns = {0:'endcount'})\n",
    "BOT10_ES_2016['endnumber'] = np.arange(1,11,1)\n",
    "BOT10_ES_2017 = DFCB_2017.groupby(['endstationid','endstationname','endstationlongitude','endstationlatitude']).size().sort_values(ascending=True).iloc[0:10].reset_index()\n",
    "BOT10_ES_2017 = BOT10_ES_2017.rename(columns = {0:'endcount'})\n",
    "BOT10_ES_2017['endnumber'] = np.arange(1,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
